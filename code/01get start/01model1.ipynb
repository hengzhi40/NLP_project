{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.model总结：\n",
    "- 模型分为根据编解码的结构分为：\n",
    "\t- 编码器模型，例如BERT; 适合做命名实体识别、文本分类、阅读理解\n",
    "\t- 解码器模型，例如GPT、bloom、LLAMA。适合做文本生成\n",
    "\t- 编码器解码器模型，例如T5，GLM\n",
    "- model Head最模型的输出进一步做映射。是一种任务头。分为\n",
    "\t- *Model只返回模型本身的内容\n",
    "\t- *ForCausalLM，解码器模型\n",
    "\t- *ForMaskedLM，编码器模型\n",
    "\t- *Seq2SeqLM\n",
    "\t- *ForSequenceClassification，分类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.模型的保存与加载\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载BERT模型\n",
    "model = AutoModel.from_pretrained(\"/gemini/pretrain3\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'rbt3'...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# 模型下载\n",
    "! git clone \"https://huggingface.co/hf1/rbt3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git: 'lfs' is not a git command. See 'git --help'.\n",
      "\n",
      "The most similar command is\n",
      "\tlog\n"
     ]
    }
   ],
   "source": [
    "! git lfs clone \"https://huggingface.co/hf1/rbt3\" --include=\"*.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.配置模型的加载参数\n",
    "model = AutoModel.from_pretrained(\"/gemini/pretrain3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"/gemini/pretrain3\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.37.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型层的参数\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"/gemini/pretrain3\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.37.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 21128\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. AutoConfig查看模型运行时的参数\n",
    "config = AutoConfig.from_pretrained(\"/gemini/pretrain3\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.attribute_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2483, 2207, 4638, 2769, 3300,  702, 1920, 1920, 4638, 3457, 2682,\n",
       "          102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.模型调用\n",
    "sen = \"弱小的我有个大大的梦想\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/gemini/pretrain3\")\n",
    "input = tokenizer(sen, return_tensors=\"pt\")\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = AutoModel.from_pretrained(\"/gemini/pretrain3\").cuda()\n",
    "    device = model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.6285,  0.1057,  0.0249,  ...,  0.4600,  0.0488, -0.4260],\n",
       "         [ 0.0029,  0.1078, -0.7839,  ..., -0.4183, -0.4560, -0.7294],\n",
       "         [ 1.4415, -1.3841, -1.0020,  ...,  0.7041, -0.1755, -0.4673],\n",
       "         ...,\n",
       "         [ 0.4306,  0.0630, -0.1104,  ...,  0.4592,  0.7441, -0.2455],\n",
       "         [ 0.1210,  0.0339, -0.3225,  ...,  0.4293,  0.3329, -0.1104],\n",
       "         [ 0.2389, -0.0932, -0.1649,  ...,  0.3371, -0.3371, -0.4923]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 9.9979e-01,  9.9998e-01,  9.9775e-01,  9.9517e-01,  9.6599e-01,\n",
       "          9.5374e-01, -9.2898e-01, -9.8111e-01,  9.9483e-01, -9.9941e-01,\n",
       "          1.0000e+00,  9.9860e-01,  2.4086e-01, -9.5973e-01,  9.9988e-01,\n",
       "         -9.9992e-01, -5.2047e-01,  9.9701e-01,  9.8733e-01,  9.2102e-03,\n",
       "          9.9988e-01, -1.0000e+00, -9.2539e-01, -3.3459e-01,  5.3460e-01,\n",
       "          9.9752e-01,  9.5977e-01, -9.8703e-01, -9.9999e-01,  9.9881e-01,\n",
       "          9.6978e-01,  9.9977e-01,  9.6819e-01, -1.0000e+00, -9.9988e-01,\n",
       "          9.2308e-01, -2.8736e-01,  9.9695e-01, -5.2923e-01, -9.3501e-01,\n",
       "         -8.8263e-01, -9.7612e-01, -5.7390e-01, -9.9798e-01, -9.7507e-01,\n",
       "          8.6257e-01, -1.0000e+00, -1.0000e+00,  8.1264e-01,  9.9997e-01,\n",
       "         -8.3680e-01, -9.9998e-01,  8.2959e-01, -3.7111e-01, -5.4551e-01,\n",
       "          9.9562e-01, -9.9991e-01,  9.7417e-01,  1.0000e+00,  9.5140e-01,\n",
       "          9.9978e-01, -9.9853e-01, -1.5458e-02, -9.9993e-01,  1.0000e+00,\n",
       "         -9.9976e-01, -9.8620e-01,  6.3787e-01,  9.9999e-01,  1.0000e+00,\n",
       "         -8.7340e-01,  9.9739e-01,  1.0000e+00,  5.2111e-01,  9.8439e-01,\n",
       "          9.9807e-01, -9.9945e-01,  7.8707e-01, -1.0000e+00, -6.6448e-01,\n",
       "          1.0000e+00,  9.9828e-01, -9.2719e-01,  9.1145e-01, -9.8800e-01,\n",
       "         -9.9995e-01, -9.9943e-01,  9.9999e-01,  1.6159e-01,  9.9117e-01,\n",
       "          9.9985e-01, -9.9955e-01, -1.0000e+00,  9.9927e-01, -9.9935e-01,\n",
       "         -9.9933e-01, -8.8905e-01,  9.9967e-01,  1.2851e-01, -9.4725e-01,\n",
       "          1.2831e-01,  9.5794e-01, -9.9627e-01, -9.9273e-01,  9.6676e-01,\n",
       "          9.9748e-01,  5.1763e-01, -9.9943e-01,  9.9999e-01,  6.7541e-01,\n",
       "         -1.0000e+00, -8.9200e-01, -9.9982e-01, -9.7158e-01, -9.9251e-01,\n",
       "          9.9993e-01, -8.9295e-02,  1.0133e-01,  9.9983e-01, -9.9664e-01,\n",
       "          8.2085e-01, -9.9939e-01, -7.9681e-01,  1.3556e-01,  9.9928e-01,\n",
       "          9.9996e-01,  9.9945e-01, -9.9939e-01,  9.9732e-01,  9.9999e-01,\n",
       "          9.6404e-01,  9.9116e-01, -9.9803e-01,  9.9105e-01,  3.4449e-01,\n",
       "         -9.8687e-01,  6.8907e-01, -9.0241e-01,  1.0000e+00,  9.8255e-01,\n",
       "          9.8462e-01, -9.9859e-01,  9.9997e-01, -9.9820e-01,  9.9999e-01,\n",
       "         -1.0000e+00,  9.9956e-01, -9.9999e-01, -9.9925e-01,  9.9960e-01,\n",
       "          9.8391e-01,  1.0000e+00, -6.2324e-01,  1.0000e+00, -9.9968e-01,\n",
       "         -9.9999e-01,  9.9406e-01,  9.1057e-01,  9.9784e-01, -9.9994e-01,\n",
       "          8.8199e-01,  2.9455e-01, -5.0983e-01, -6.6870e-01, -1.0000e+00,\n",
       "          9.9993e-01, -9.0001e-01,  1.0000e+00,  9.9611e-01, -9.0725e-01,\n",
       "         -9.7006e-01, -9.9814e-01,  9.4681e-01, -9.9979e-01, -9.8099e-01,\n",
       "          9.9554e-01,  3.4825e-01,  9.9927e-01, -8.9544e-01, -9.4278e-01,\n",
       "          9.8956e-01, -7.7823e-01, -9.9999e-01,  9.9461e-01, -5.2862e-01,\n",
       "          9.8901e-01,  8.8665e-01, -2.8344e-01,  8.5568e-01,  5.3839e-01,\n",
       "         -9.0565e-01,  1.0000e+00,  6.6872e-01,  9.8360e-01,  9.9975e-01,\n",
       "          3.0576e-01, -9.6142e-01, -9.8706e-01, -9.9998e-01, -7.9543e-01,\n",
       "          1.0000e+00, -6.7338e-01, -9.9981e-01,  8.7221e-01, -9.9999e-01,\n",
       "          7.5142e-01, -8.2787e-01, -5.2262e-01, -9.9921e-01, -9.9995e-01,\n",
       "          9.9986e-01, -9.7005e-01, -9.9929e-01,  4.1668e-01, -5.0080e-01,\n",
       "         -5.5257e-01, -9.9989e-01,  6.2760e-01,  9.7298e-01, -1.7034e-01,\n",
       "          9.4385e-01, -8.7038e-01, -9.9977e-01,  9.9866e-01, -9.7037e-01,\n",
       "          5.1116e-01,  9.0440e-01,  1.0000e+00,  9.8087e-01, -5.0600e-01,\n",
       "         -5.0243e-01,  9.9980e-01,  4.1868e-01, -1.0000e+00,  9.0071e-01,\n",
       "         -9.9825e-01,  4.8874e-02,  9.9989e-01, -9.9765e-01,  7.8084e-01,\n",
       "          9.9999e-01,  9.8956e-01,  1.0000e+00, -7.2364e-01, -9.9917e-01,\n",
       "         -9.9866e-01,  1.0000e+00,  9.7429e-01,  9.9992e-01, -9.9990e-01,\n",
       "         -9.9950e-01,  8.2810e-01, -9.9659e-01, -1.0000e+00, -9.9971e-01,\n",
       "         -6.6365e-01,  9.9520e-01,  1.0000e+00,  1.8623e-01, -9.9982e-01,\n",
       "         -9.8250e-01, -9.9941e-01,  9.9999e-01, -9.9783e-01,  9.9997e-01,\n",
       "          9.0963e-01, -9.9856e-01, -9.9148e-01, -2.3686e-01, -9.7072e-01,\n",
       "         -9.9929e-01,  7.4173e-01, -9.9999e-01, -9.9422e-01, -9.9993e-01,\n",
       "          9.8287e-01, -9.9984e-01, -1.0000e+00,  9.4779e-01,  9.9996e-01,\n",
       "          8.9340e-01, -9.9999e-01,  9.9991e-01,  9.9936e-01, -5.3889e-01,\n",
       "         -9.9930e-01,  9.6943e-01, -1.0000e+00,  1.0000e+00, -9.9828e-01,\n",
       "          9.4230e-01, -8.9323e-01, -9.9144e-01,  8.7629e-01,  9.9984e-01,\n",
       "          9.9994e-01, -9.8638e-01,  3.3101e-01, -9.7363e-01, -9.9242e-01,\n",
       "         -1.1690e-01,  9.8725e-01, -5.6207e-01,  8.8971e-01, -9.4360e-01,\n",
       "         -5.0414e-01,  8.7676e-01, -9.7837e-01, -9.9994e-01,  9.5331e-01,\n",
       "          1.0000e+00, -9.3189e-01,  1.0000e+00,  9.8202e-01,  1.0000e+00,\n",
       "          9.3447e-01, -9.9962e-01,  9.9968e-01,  9.4435e-01, -9.6585e-01,\n",
       "         -9.9235e-01, -9.9052e-01,  9.1929e-01,  6.3333e-01, -4.7836e-01,\n",
       "         -9.9994e-01,  9.9998e-01,  9.9282e-01,  9.9182e-01,  8.5069e-01,\n",
       "         -3.8942e-01,  1.7251e-01,  9.4516e-01, -9.9888e-01,  9.9822e-01,\n",
       "         -9.9983e-01, -9.7948e-01,  9.9968e-01,  9.9998e-01,  9.9957e-01,\n",
       "          6.6284e-01, -9.3163e-01,  9.9816e-01, -9.9780e-01,  9.9857e-01,\n",
       "         -9.9986e-01,  9.9956e-01, -9.8265e-01,  8.7195e-01, -9.3070e-01,\n",
       "         -9.9822e-01,  9.9998e-01,  9.9678e-01, -8.9517e-01,  9.9991e-01,\n",
       "         -9.3974e-01,  9.8982e-01,  9.9091e-01,  9.9749e-01,  9.6368e-01,\n",
       "          9.7590e-01,  9.9999e-01, -9.9321e-01, -9.7885e-01, -9.8727e-01,\n",
       "         -9.9567e-01, -9.9896e-01, -1.0000e+00,  4.2500e-01, -9.9967e-01,\n",
       "         -9.8973e-01, -4.5558e-01,  8.7053e-01,  9.5145e-01, -7.7955e-01,\n",
       "          4.3059e-01, -2.1650e-01,  4.6862e-01, -9.0388e-01,  5.6120e-01,\n",
       "          9.8950e-01, -9.9599e-01, -9.8946e-01, -9.9999e-01, -9.9868e-01,\n",
       "          8.9133e-01,  9.9999e-01, -9.9999e-01,  9.9817e-01, -9.9995e-01,\n",
       "         -9.9931e-01,  9.9966e-01, -9.6266e-01, -9.6575e-01,  9.9968e-01,\n",
       "         -1.0000e+00,  9.7059e-01,  9.9998e-01,  1.0000e+00,  9.9878e-01,\n",
       "          9.9998e-01, -9.4440e-01, -9.9988e-01, -9.9985e-01, -9.9999e-01,\n",
       "         -1.0000e+00, -9.9999e-01,  9.3967e-01, -4.4784e-01, -9.9998e-01,\n",
       "         -8.1887e-01,  9.8454e-01,  1.0000e+00,  9.7004e-01, -9.9928e-01,\n",
       "          8.5546e-02, -9.9938e-01, -9.8936e-01,  9.9662e-01, -7.9159e-01,\n",
       "         -9.9996e-01,  9.7830e-01, -5.2410e-01,  9.9998e-01, -8.3376e-01,\n",
       "          9.4355e-01,  9.1183e-01,  8.8346e-01,  9.9212e-01, -9.9999e-01,\n",
       "          8.5629e-01,  9.9999e-01,  8.0562e-01, -9.9999e-01, -8.7307e-01,\n",
       "         -9.4307e-01, -1.0000e+00, -3.4530e-01,  8.3505e-01,  9.9998e-01,\n",
       "         -1.0000e+00, -8.0912e-01, -9.9722e-01,  9.2409e-01,  9.9458e-01,\n",
       "          9.9991e-01,  9.9976e-01,  9.5219e-01,  9.3942e-01,  9.9059e-01,\n",
       "          2.8448e-01,  9.9996e-01,  3.3695e-01, -9.9853e-01,  9.9888e-01,\n",
       "         -8.3897e-01,  1.5041e-01, -9.9961e-01,  9.9912e-01,  4.1701e-01,\n",
       "          9.9999e-01,  9.9362e-01, -7.4556e-01, -9.8878e-01, -9.9054e-01,\n",
       "          9.8402e-01,  1.0000e+00, -9.9677e-01, -9.8803e-01, -9.9939e-01,\n",
       "         -9.9997e-01, -9.9755e-01, -8.5749e-01,  1.6405e-01, -9.8857e-01,\n",
       "         -9.9950e-01,  7.9592e-01,  9.8209e-01,  1.0000e+00,  1.0000e+00,\n",
       "          9.9991e-01, -9.6914e-01, -8.9228e-01,  9.9480e-01, -3.7786e-01,\n",
       "          9.5993e-01, -9.6552e-01, -1.0000e+00, -9.9847e-01, -9.9993e-01,\n",
       "          9.9998e-01, -7.2606e-01, -7.8135e-01, -7.9364e-01, -5.9918e-02,\n",
       "          8.5451e-01, -9.9993e-01, -6.6248e-01, -9.9947e-01,  9.2317e-01,\n",
       "          1.0000e+00, -9.9955e-01,  9.9959e-01, -9.9932e-01,  5.7930e-01,\n",
       "          6.2128e-01,  8.1165e-01,  9.9978e-01, -7.6463e-01, -1.0030e-01,\n",
       "         -5.0479e-01,  1.0914e-01,  9.6373e-01,  9.9812e-01, -9.7917e-01,\n",
       "          4.4209e-01,  9.9951e-01, -8.8867e-01,  9.9998e-01,  3.5005e-01,\n",
       "          9.4859e-01,  8.7357e-01,  9.9998e-01,  8.5061e-01,  9.9992e-01,\n",
       "          9.9719e-01,  9.9998e-01,  9.9995e-01, -9.7701e-01,  3.2451e-01,\n",
       "          3.1665e-01, -9.3702e-01, -6.4386e-01,  9.2177e-01,  9.9990e-01,\n",
       "          2.7559e-01, -9.4016e-01, -9.9964e-01,  9.9595e-01,  9.9994e-01,\n",
       "          1.0000e+00,  2.1402e-01,  9.9846e-01,  5.2777e-01,  8.3179e-01,\n",
       "          8.1190e-01,  9.1815e-01,  5.3485e-01,  5.4084e-01,  9.9918e-01,\n",
       "          9.9948e-01, -9.9994e-01, -9.9991e-01, -1.0000e+00,  1.0000e+00,\n",
       "          9.9994e-01, -9.7283e-01, -1.0000e+00,  9.9982e-01, -9.2187e-01,\n",
       "          8.3279e-01,  9.9523e-01,  6.1174e-01, -9.1291e-01,  9.1451e-01,\n",
       "         -9.9968e-01, -4.4291e-02,  9.3379e-01,  8.5434e-01,  7.2279e-01,\n",
       "          9.9989e-01, -9.9995e-01,  4.1494e-01,  9.9999e-01, -8.1818e-01,\n",
       "          9.9999e-01,  5.6093e-02, -9.9762e-01,  9.9942e-01, -9.9566e-01,\n",
       "         -9.9995e-01, -4.9008e-01,  9.9999e-01,  9.9933e-01,  2.6053e-01,\n",
       "         -9.3192e-01,  9.9989e-01, -9.9997e-01,  9.9995e-01, -9.9993e-01,\n",
       "          2.6222e-01, -9.9945e-01,  9.9990e-01, -9.8499e-01, -9.9973e-01,\n",
       "         -9.4538e-01,  9.8774e-01,  9.0189e-01, -7.8471e-01,  9.9996e-01,\n",
       "         -4.2850e-01, -9.6290e-01,  1.4236e-01, -9.8515e-01, -9.9806e-01,\n",
       "         -9.8276e-01, -2.1509e-01, -9.9999e-01,  7.6921e-01,  9.1810e-01,\n",
       "         -9.0200e-01, -9.9883e-01, -9.9999e-01,  9.9999e-01, -9.3149e-01,\n",
       "         -9.8517e-01,  9.9996e-01, -9.5417e-01, -1.0000e+00,  9.7032e-01,\n",
       "         -9.9870e-01,  3.1255e-01,  9.8613e-01,  9.0427e-01,  7.2378e-02,\n",
       "         -9.9999e-01,  7.1512e-01,  9.9999e-01, -9.9660e-01, -9.2810e-01,\n",
       "         -7.2866e-01, -9.8939e-01,  9.6621e-01,  9.9881e-01,  9.5975e-01,\n",
       "         -8.9382e-01,  9.6117e-01,  9.9790e-01,  9.0911e-01, -3.6833e-01,\n",
       "          8.0666e-01, -9.9893e-01, -9.9993e-01, -9.9582e-01, -9.9052e-01,\n",
       "         -9.9999e-01, -9.9997e-01,  1.0000e+00,  9.9997e-01,  9.9999e-01,\n",
       "         -9.0375e-01, -8.6228e-01,  9.6776e-01,  9.9640e-01, -9.9986e-01,\n",
       "         -9.5896e-02,  2.9592e-01,  9.7001e-01, -8.7991e-05, -9.9957e-01,\n",
       "         -5.2182e-01, -1.0000e+00, -8.8445e-01,  2.4472e-01, -5.4933e-01,\n",
       "          8.4428e-01,  9.9999e-01,  9.9998e-01, -9.9991e-01, -9.9745e-01,\n",
       "         -9.9571e-01, -9.9977e-01,  9.9995e-01,  9.9973e-01,  9.9971e-01,\n",
       "         -9.7334e-01, -8.1919e-01,  9.9737e-01,  8.1247e-02,  2.9742e-02,\n",
       "         -9.9973e-01, -9.9380e-01, -9.9999e-01,  8.7158e-01, -9.9846e-01,\n",
       "         -9.9998e-01,  9.9953e-01,  9.9999e-01,  8.0434e-01, -9.9997e-01,\n",
       "         -9.1272e-01,  1.0000e+00,  9.9757e-01,  1.0000e+00,  8.3924e-01,\n",
       "          9.9995e-01, -9.8885e-01,  9.9655e-01, -9.9586e-01,  9.9999e-01,\n",
       "         -1.0000e+00,  1.0000e+00,  9.9996e-01,  9.9900e-01,  9.9767e-01,\n",
       "         -9.8795e-01,  7.2715e-01, -9.6017e-01, -2.5973e-01,  9.4793e-01,\n",
       "         -2.3730e-01, -9.8841e-01, -3.3864e-01,  9.5449e-01, -9.6836e-01,\n",
       "          1.0000e+00,  4.3197e-01, -3.4757e-01,  8.7355e-01,  8.3994e-01,\n",
       "          9.9919e-01, -8.6627e-01, -9.9943e-01,  9.9185e-01,  9.9704e-01,\n",
       "          9.8893e-01,  1.0000e+00,  9.8049e-01,  9.9999e-01, -9.6689e-01,\n",
       "         -9.9965e-01,  9.9630e-01, -8.5995e-01, -3.7270e-01, -9.9997e-01,\n",
       "          9.9999e-01,  9.9984e-01, -9.9999e-01, -9.6197e-01, -5.4421e-02,\n",
       "          5.9368e-01,  9.9999e-01,  9.9923e-01,  9.9641e-01,  8.9657e-01,\n",
       "          8.6104e-01,  9.9975e-01, -9.9829e-01,  9.9548e-01, -9.9541e-01,\n",
       "         -9.9054e-01,  9.9999e-01, -9.9336e-01,  9.9989e-01, -9.7827e-01,\n",
       "          9.9919e-01, -9.9957e-01,  9.1996e-01,  9.7521e-01,  8.9134e-01,\n",
       "         -9.9476e-01,  1.0000e+00,  8.1297e-01, -9.9812e-01, -9.9895e-01,\n",
       "         -9.8447e-01, -9.9868e-01,  8.9507e-01]], device='cuda:0',\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输出的结果\n",
    "input.to(device)\n",
    "output = model(**input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /gemini/pretrain3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.使用带model head的模型\n",
    "from transformers import AutoModelForSequenceClassification,BertForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/gemini/pretrain3\",num_labels=10).to(\"cuda:0\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.0195, -0.1944,  0.6337,  0.7816,  0.3433,  0.9622,  0.4997,  0.7193,\n",
       "          0.2064, -0.5637]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mApplication will exit soon in 3600 seconds which is set by env\"ORION_TASK_IDLE_TIME\".\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 现在是一个二分类，默认的结果。分类的类型可以进行调整\n",
    "output = model(**input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
